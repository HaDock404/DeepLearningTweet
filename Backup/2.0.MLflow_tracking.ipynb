{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation des données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib et seaborn pour les représentations graphiques\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# Suppression des alertes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>awww thats bummer you shoulda got david carr ...</td>\n",
       "      <td>awww thats bummer shoulda get david carr third...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>dived many times for the ball managed to save...</td>\n",
       "      <td>dive many time ball manage save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>no its not behaving at all im mad why am here ...</td>\n",
       "      <td>behaving im mad cant see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>just woke up having no school is the best feel...</td>\n",
       "      <td>woke school best feel ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>thewdbcom very cool to hear old walt interviews</td>\n",
       "      <td>thewdbcom cool hear old walt interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
       "      <td>ready mojo makeover ask detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>happy th birthday to my boo of alll time tupac...</td>\n",
       "      <td>happy th birthday boo alll time tupac amaru sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target          id                          date      flag  \\\n",
       "0             0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1599995       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \\\n",
       "0        _TheSpecialOne_   awww thats bummer you shoulda got david carr ...   \n",
       "1          scotthamilton  is upset that he cant update his facebook by t...   \n",
       "2               mattycus   dived many times for the ball managed to save...   \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4                 Karoli  no its not behaving at all im mad why am here ...   \n",
       "...                  ...                                                ...   \n",
       "1599995  AmandaMarie1028  just woke up having no school is the best feel...   \n",
       "1599996      TheWDBoards   thewdbcom very cool to hear old walt interviews    \n",
       "1599997           bpbabe  are you ready for your mojo makeover ask me fo...   \n",
       "1599998     tinydiamondz  happy th birthday to my boo of alll time tupac...   \n",
       "1599999   RyanTrevMorris                              happy charitytuesday    \n",
       "\n",
       "                                                     words  \n",
       "0        awww thats bummer shoulda get david carr third...  \n",
       "1        upset cant update facebook texting might cry r...  \n",
       "2            dive many time ball manage save rest go bound  \n",
       "3                          whole body feel itchy like fire  \n",
       "4                                 behaving im mad cant see  \n",
       "...                                                    ...  \n",
       "1599995                         woke school best feel ever  \n",
       "1599996             thewdbcom cool hear old walt interview  \n",
       "1599997                     ready mojo makeover ask detail  \n",
       "1599998  happy th birthday boo alll time tupac amaru sh...  \n",
       "1599999                               happy charitytuesday  \n",
       "\n",
       "[1600000 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/2.cleaned_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "df = df.dropna(subset=['words'])\n",
    "\n",
    "X_CountVecorizer = vectorizer.fit_transform(df['words'])\n",
    "y_CountVecorizer = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_TfidfVectorizer = vectorizer.fit_transform(df['words'])\n",
    "y_TfidfVectorizer = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_Cv, X_test_Cv, y_train_Cv, y_test_Cv = train_test_split(X_CountVecorizer,\n",
    "                                                                 y_CountVecorizer,\n",
    "                                                                 test_size = 0.4,\n",
    "                                                                 random_state = 42)\n",
    "\n",
    "X_train_Tv, X_test_Tv, y_train_Tv, y_test_Tv = train_test_split(X_TfidfVectorizer,\n",
    "                                                                 y_TfidfVectorizer,\n",
    "                                                                 test_size = 0.4,\n",
    "                                                                 random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data,\n",
    "    data.target,\n",
    "    test_size = 0.4,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<955675x409246 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6637781 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_Cv, y_train_Cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/19 17:29:42 INFO mlflow.tracking.fluent: Experiment with name 'Reg_Logistic_Models' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"Reg_Logistic_Models\")\n",
    "mlflow.sklearn.autolog() \n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_defaut'):\n",
    "  clf = LogisticRegression()\n",
    "  clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name = 'reg_logistic_defaut'):\n",
    "  clf = LogisticRegression()\n",
    "  clf.fit(X_train_Cv, y_train_Cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"Reg_Logistic_CountVectorizer\")\n",
    "mlflow.sklearn.autolog() \n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_SolverLiblinear'):\n",
    "  clf = LogisticRegression(solver='liblinear')\n",
    "  clf.fit(X_train_Cv, y_train_Cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name = 'reg_logistic_penalty11'):\n",
    "  clf = LogisticRegression(penalty=11)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_penalty12'):\n",
    "  clf = LogisticRegression(penalty=12)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_maxIter100'):\n",
    "  clf = LogisticRegression(max_iter=100)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_maxIter200'):\n",
    "  clf = LogisticRegression(max_iter=200)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_maxIter300'):\n",
    "  clf = LogisticRegression(max_iter=300)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_SolverLiblinear'):\n",
    "  clf = LogisticRegression(solver='liblinear')\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_SolverSaga'):\n",
    "  clf = LogisticRegression(solver='saga')\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_C0.001'):\n",
    "  clf = LogisticRegression(C=0.001)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_C0.01'):\n",
    "  clf = LogisticRegression(C=0.01)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_C0.1'):\n",
    "  clf = LogisticRegression(C=0.1)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_C1'):\n",
    "  clf = LogisticRegression(C=1)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_C10'):\n",
    "  clf = LogisticRegression(C=10)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_C100'):\n",
    "  clf = LogisticRegression(C=100)\n",
    "  clf.fit(X_train_Cv, y_train_Cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Reg_Logistic_TfidfVectorizer\")\n",
    "mlflow.sklearn.autolog() \n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_defaut'):\n",
    "  clf = LogisticRegression()\n",
    "  clf.fit(X_train_Tv, y_train_Tv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_penalty11'):\n",
    "  clf = LogisticRegression(penalty=11)\n",
    "  clf.fit(X_train_Tv, y_train_Tv)\n",
    "\n",
    "with mlflow.start_run(run_name = 'reg_logistic_penalty11'):\n",
    "  clf = LogisticRegression(penalty=11)\n",
    "  clf.fit(X_train_Tv, y_train_Tv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet7Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

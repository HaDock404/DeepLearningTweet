{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation des données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib et seaborn pour les représentations graphiques\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# sklearn preprocessing pour le traiter les variables catégorielles\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Gestion du système de fichiers\n",
    "import os\n",
    "\n",
    "# Suppression des alertes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/2.sample_dataset.csv\")\n",
    "df = df.dropna(subset=['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 11:56:57.507109: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build & train Word2Vec model ...\n",
      "Vocabulary size: 61\n",
      "Word2Vec trained\n"
     ]
    }
   ],
   "source": [
    "# Création et entraînement du modèle Word2Vec\n",
    "w2v_size=300\n",
    "w2v_window=5\n",
    "w2v_min_count=1\n",
    "w2v_epochs=100\n",
    "\n",
    "sentences = df['words'].to_list()\n",
    "\n",
    "print(\"Build & train Word2Vec model ...\")\n",
    "w2v_model = gensim.models.Word2Vec(min_count=w2v_min_count, window=w2v_window,\n",
    "                                                vector_size=w2v_size,\n",
    "                                                seed=42,\n",
    "                                                workers=1)\n",
    "#                                                workers=multiprocessing.cpu_count())\n",
    "w2v_model.build_vocab(sentences)\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=w2v_epochs)\n",
    "model_vectors = w2v_model.wv\n",
    "w2v_words = model_vectors.index_to_key\n",
    "print(\"Vocabulary size: %i\" % len(w2v_words))\n",
    "print(\"Word2Vec trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Tokenizer ...\n",
      "Number of unique words: 292434\n"
     ]
    }
   ],
   "source": [
    "# Préparation des sentences (tokenization)\n",
    "maxlen = 24 # adapt to length of sentences\n",
    "\n",
    "print(\"Fit Tokenizer ...\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "x_sentences = pad_sequences(tokenizer.texts_to_sequences(sentences),\n",
    "                                                     maxlen=maxlen,\n",
    "                                                     padding='post') \n",
    "                                                   \n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "print(\"Number of unique words: %i\" % num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Embedding matrix ...\n",
      "Word embedding rate :  0.0001\n",
      "Embedding matrix: (292434, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"Create Embedding matrix ...\")\n",
    "w2v_size = 300\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, w2v_size))\n",
    "i=0\n",
    "j=0\n",
    "    \n",
    "for word, idx in word_index.items():\n",
    "    i +=1\n",
    "    if word in w2v_words:\n",
    "        j +=1\n",
    "        embedding_vector = model_vectors[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[idx] = model_vectors[word]\n",
    "            \n",
    "word_rate = np.round(j/i,4)\n",
    "print(\"Word embedding rate : \", word_rate)\n",
    "print(\"Embedding matrix: %s\" % str(embedding_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = df['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_sentences, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sets = [\n",
    "    {'learning_rate': 0.01},\n",
    "    {'learning_rate': 0.1},\n",
    "    {'learning_rate': 0.2},\n",
    "    {'n_estimators': 100},\n",
    "    {'n_estimators': 200},\n",
    "    {'n_estimators': 300},\n",
    "    {'max_depth': 3},\n",
    "    {'max_depth': 4},\n",
    "    {'max_depth': 5},\n",
    "    {'subsample': 0.8},\n",
    "    {'subsample': 0.9},\n",
    "    {'subsample': 1},\n",
    "    {'colsample_bytree': 0.8},\n",
    "    {'colsample_bytree': 0.9},\n",
    "    {'colsample_bytree': 1},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/01 13:04:29 INFO mlflow.tracking.fluent: Experiment with name 'W2V_XGBoostClassifier' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "artifact_path = './artifacts/'\n",
    "\n",
    "mlflow.set_experiment(\"W2V_XGBoostClassifier\")\n",
    "\n",
    "for i, params in enumerate(param_sets):\n",
    "    name_experience = f'{list(params.keys())[0]}_{list(params.values())[0]}' # héhéhéhé ça marche\n",
    "    with mlflow.start_run(run_name=f\"W2V_XGBoostClf{name_experience}\"):\n",
    "        clf = XGBClassifier(**params)\n",
    "        clf.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        mlflow.log_param(\"params\", params)\n",
    "        mlflow.log_metric(\"accuracy\", clf.score(X_test, y_test))\n",
    "        mlflow.log_metric(\"Precision\", precision_score(y_test, y_pred))\n",
    "        mlflow.log_metric(\"Recall\", recall_score(y_test, y_pred))\n",
    "        mlflow.log_metric(\"F1_Score\", f1_score(y_test, y_pred))\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        mlflow.log_metric(\"AUC\", roc_auc)\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        conf_matrix_path = f\"{artifact_path}confMat_W2V_XGBoostClf_{name_experience}.csv\"\n",
    "        pd.DataFrame(conf_matrix).to_csv(conf_matrix_path, index=False, header=False)\n",
    "        mlflow.log_artifact(conf_matrix_path, \"metrics\")\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        roc_curve_path = f\"{artifact_path}roc_W2V_XGBoostClf_{name_experience}.png\"\n",
    "        plt.savefig(roc_curve_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(roc_curve_path, \"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet7Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

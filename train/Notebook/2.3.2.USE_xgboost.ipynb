{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation des données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib et seaborn pour les représentations graphiques\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# sklearn preprocessing pour le traiter les variables catégorielles\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Gestion du système de fichiers\n",
    "import os\n",
    "\n",
    "# Suppression des alertes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/2.sample_dataset.csv\")\n",
    "df = df.dropna(subset=['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 12:45:27.390166: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='1'\n",
    "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"] = \"UNCOMPRESSED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 12:45:33.522654: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import shutil\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_USE_fct(sentences, b_size) :\n",
    "    batch_size = b_size\n",
    "\n",
    "    features = None\n",
    "\n",
    "    for step in range(len(sentences)//batch_size) :\n",
    "        idx = step*batch_size\n",
    "        feat = embed(sentences[idx:idx+batch_size])\n",
    "\n",
    "        if step ==0 :\n",
    "            features = feat\n",
    "        else :\n",
    "            features = np.concatenate((features,feat))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "sentences = df['words'].sample(100000, random_state=42)\n",
    "sentences = sentences.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sentences = feature_USE_fct(sentences, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = df['target'].sample(100000, random_state=42)\n",
    "labels = labels.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_sentences, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sets = [\n",
    "    {'learning_rate': 0.01},\n",
    "    {'learning_rate': 0.1},\n",
    "    {'learning_rate': 0.2},\n",
    "    {'n_estimators': 100},\n",
    "    {'n_estimators': 200},\n",
    "    {'n_estimators': 300},\n",
    "    {'max_depth': 3},\n",
    "    {'max_depth': 4},\n",
    "    {'max_depth': 5},\n",
    "    {'subsample': 0.8},\n",
    "    {'subsample': 0.9},\n",
    "    {'subsample': 1},\n",
    "    {'colsample_bytree': 0.8},\n",
    "    {'colsample_bytree': 0.9},\n",
    "    {'colsample_bytree': 1},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/01 13:10:24 INFO mlflow.tracking.fluent: Experiment with name 'USE_XGBoostClassifier' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "artifact_path = './artifacts/'\n",
    "\n",
    "mlflow.set_experiment(\"USE_XGBoostClassifier\")\n",
    "\n",
    "for i, params in enumerate(param_sets):\n",
    "    name_experience = f'{list(params.keys())[0]}_{list(params.values())[0]}' # héhéhéhé ça marche\n",
    "    with mlflow.start_run(run_name=f\"USE_XGBoostClf{name_experience}\"):\n",
    "        clf = XGBClassifier(**params)\n",
    "        clf.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        mlflow.log_param(\"params\", params)\n",
    "        mlflow.log_metric(\"accuracy\", clf.score(X_test, y_test))\n",
    "        mlflow.log_metric(\"Precision\", precision_score(y_test, y_pred))\n",
    "        mlflow.log_metric(\"Recall\", recall_score(y_test, y_pred))\n",
    "        mlflow.log_metric(\"F1_Score\", f1_score(y_test, y_pred))\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        mlflow.log_metric(\"AUC\", roc_auc)\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        conf_matrix_path = f\"{artifact_path}confMat_USE_XGBoostClf_{name_experience}.csv\"\n",
    "        pd.DataFrame(conf_matrix).to_csv(conf_matrix_path, index=False, header=False)\n",
    "        mlflow.log_artifact(conf_matrix_path, \"metrics\")\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        roc_curve_path = f\"{artifact_path}roc_USE_XGBoostClf_{name_experience}.png\"\n",
    "        plt.savefig(roc_curve_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(roc_curve_path, \"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet7Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation des données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib et seaborn pour les représentations graphiques\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# sklearn preprocessing pour le traiter les variables catégorielles\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Gestion du système de fichiers\n",
    "import os\n",
    "\n",
    "# Suppression des alertes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>486066</th>\n",
       "      <td>1</td>\n",
       "      <td>1564732376</td>\n",
       "      <td>Mon Apr 20 04:43:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>john1954moi</td>\n",
       "      <td>hey no problem like getting followers and im p...</td>\n",
       "      <td>hey problem like get follower im pleased follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834217</th>\n",
       "      <td>1</td>\n",
       "      <td>2059479762</td>\n",
       "      <td>Sat Jun 06 17:01:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Hinn888</td>\n",
       "      <td>thanks</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844489</th>\n",
       "      <td>0</td>\n",
       "      <td>1996685745</td>\n",
       "      <td>Mon Jun 01 15:30:36 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>queenbmakeup</td>\n",
       "      <td>have this nail strengther from them but nothi...</td>\n",
       "      <td>nail strengther nothing work nail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179878</th>\n",
       "      <td>1</td>\n",
       "      <td>1967004216</td>\n",
       "      <td>Fri May 29 18:47:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>angelope</td>\n",
       "      <td>waiting for the decemberists</td>\n",
       "      <td>wait decemberists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244128</th>\n",
       "      <td>1</td>\n",
       "      <td>1976584126</td>\n",
       "      <td>Sat May 30 18:30:30 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>wbgookin</td>\n",
       "      <td>herb tarlek on wkrp could but only if he wore ...</td>\n",
       "      <td>herb tarlek wkrp could wore white shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922825</th>\n",
       "      <td>1</td>\n",
       "      <td>2002545720</td>\n",
       "      <td>Tue Jun 02 04:31:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>iLoveFry_</td>\n",
       "      <td>my personal feeling is that everyone should go...</td>\n",
       "      <td>personal feel everyone go buy paolo nutinis ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973226</th>\n",
       "      <td>0</td>\n",
       "      <td>2068855166</td>\n",
       "      <td>Sun Jun 07 14:49:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>JamieLeann215</td>\n",
       "      <td>just finished helping move buncha stuff now im...</td>\n",
       "      <td>finish help move buncha stuff im wait lay neig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615817</th>\n",
       "      <td>1</td>\n",
       "      <td>1824267208</td>\n",
       "      <td>Sun May 17 00:40:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>JoeRialiS</td>\n",
       "      <td>omg finished from see your video quotheyquot i...</td>\n",
       "      <td>omg finish see video quotheyquot amaze funny l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107004</th>\n",
       "      <td>1</td>\n",
       "      <td>1833727993</td>\n",
       "      <td>Mon May 18 00:14:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jeffwidman</td>\n",
       "      <td>great dinner and crew memorable momentwhen six...</td>\n",
       "      <td>great dinner crew memorable momentwhen six peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35549</th>\n",
       "      <td>0</td>\n",
       "      <td>2179252463</td>\n",
       "      <td>Mon Jun 15 08:51:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>fannsim</td>\n",
       "      <td>wai you</td>\n",
       "      <td>wai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target          id                          date      flag  \\\n",
       "486066       1  1564732376  Mon Apr 20 04:43:34 PDT 2009  NO_QUERY   \n",
       "834217       1  2059479762  Sat Jun 06 17:01:07 PDT 2009  NO_QUERY   \n",
       "844489       0  1996685745  Mon Jun 01 15:30:36 PDT 2009  NO_QUERY   \n",
       "179878       1  1967004216  Fri May 29 18:47:52 PDT 2009  NO_QUERY   \n",
       "244128       1  1976584126  Sat May 30 18:30:30 PDT 2009  NO_QUERY   \n",
       "...        ...         ...                           ...       ...   \n",
       "922825       1  2002545720  Tue Jun 02 04:31:18 PDT 2009  NO_QUERY   \n",
       "973226       0  2068855166  Sun Jun 07 14:49:21 PDT 2009  NO_QUERY   \n",
       "615817       1  1824267208  Sun May 17 00:40:20 PDT 2009  NO_QUERY   \n",
       "107004       1  1833727993  Mon May 18 00:14:56 PDT 2009  NO_QUERY   \n",
       "35549        0  2179252463  Mon Jun 15 08:51:12 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                               text  \\\n",
       "486066    john1954moi  hey no problem like getting followers and im p...   \n",
       "834217        Hinn888                                            thanks    \n",
       "844489   queenbmakeup   have this nail strengther from them but nothi...   \n",
       "179878       angelope                      waiting for the decemberists    \n",
       "244128       wbgookin  herb tarlek on wkrp could but only if he wore ...   \n",
       "...               ...                                                ...   \n",
       "922825      iLoveFry_  my personal feeling is that everyone should go...   \n",
       "973226  JamieLeann215  just finished helping move buncha stuff now im...   \n",
       "615817      JoeRialiS  omg finished from see your video quotheyquot i...   \n",
       "107004     jeffwidman  great dinner and crew memorable momentwhen six...   \n",
       "35549         fannsim                                           wai you    \n",
       "\n",
       "                                                    words  \n",
       "486066  hey problem like get follower im pleased follo...  \n",
       "834217                                             thanks  \n",
       "844489                  nail strengther nothing work nail  \n",
       "179878                                  wait decemberists  \n",
       "244128             herb tarlek wkrp could wore white shoe  \n",
       "...                                                   ...  \n",
       "922825  personal feel everyone go buy paolo nutinis ne...  \n",
       "973226  finish help move buncha stuff im wait lay neig...  \n",
       "615817  omg finish see video quotheyquot amaze funny l...  \n",
       "107004  great dinner crew memorable momentwhen six peo...  \n",
       "35549                                                 wai  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/2.sample_dataset.csv\")\n",
    "df = df.dropna(subset=['words'])\n",
    "df = df.sample(1000, random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n",
      "(800,)\n",
      "(200,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "X = df['words']\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data, tokenizer, max_length=128):\n",
    "    tokenized_data = tokenizer(data.tolist(), max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return tokenized_data\n",
    "\n",
    "train_tokenized = tokenize_data(X_train, tokenizer)\n",
    "test_tokenized = tokenize_data(X_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_tokenized['input_ids'], train_tokenized['attention_mask'], torch.tensor(y_train.tolist()))\n",
    "test_data = TensorDataset(test_tokenized['input_ids'], test_tokenized['attention_mask'], torch.tensor(y_test.tolist()))\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for input_ids, attention_mask, labels in train_loader:\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "#model.save_pretrained(\"path/to/save/fine-tuned-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5950\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, labels in test_loader:\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        predictions.extend(predicted_labels)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet7Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
